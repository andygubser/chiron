---
title: "Prognolite Projektarbeit"
author: "Michèle Odermatt und Andy Gubser"
date: "18. Oktober 2019"
output: 
  html_document:
    theme: flatly
    toc: true
    toc_depth: 4
    toc_float: 
      collapsed: true
      smooth_scroll: true
    number_sections: true
    df_print: paged
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#+++++++++++++++++++++++++
# Computing of correlation matrix
#+++++++++++++++++++++++++
# Required package : corrplot
# x : matrix
# type: possible values are "lower" (default), "upper", "full" or "flatten";
  #display lower or upper triangular of the matrix, full  or flatten matrix.
# graph : if TRUE, a correlogram or heatmap is plotted
# graphType : possible values are "correlogram" or "heatmap"
# col: colors to use for the correlogram
# ... : Further arguments to be passed to cor or cor.test function
# Result is a list including the following components :
  # r : correlation matrix, p :  p-values
  # sym : Symbolic number coding of the correlation matrix
rquery.cormat<-function(x,
                        type=c('lower', 'upper', 'full', 'flatten'),
                        graph=TRUE,
                        graphType=c("correlogram", "heatmap"),
                        col=NULL, ...)
{
  library(corrplot)
  # Helper functions
  #+++++++++++++++++
  # Compute the matrix of correlation p-values
  cor.pmat <- function(x, ...) {
    mat <- as.matrix(x)
    n <- ncol(mat)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
      for (j in (i + 1):n) {
        tmp <- cor.test(mat[, i], mat[, j], ...)
        p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
      }
    }
    colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
    p.mat
  }
  # Get lower triangle of the matrix
  getLower.tri<-function(mat){
    upper<-mat
    upper[upper.tri(mat)]<-""
    mat<-as.data.frame(upper)
    mat
  }
  # Get upper triangle of the matrix
  getUpper.tri<-function(mat){
    lt<-mat
    lt[lower.tri(mat)]<-""
    mat<-as.data.frame(lt)
    mat
  }
  # Get flatten matrix
  flattenCorrMatrix <- function(cormat, pmat) {
    ut <- upper.tri(cormat)
    data.frame(
      row = rownames(cormat)[row(cormat)[ut]],
      column = rownames(cormat)[col(cormat)[ut]],
      cor  =(cormat)[ut],
      p = pmat[ut]
    )
  }
  # Define color
  if (is.null(col)) {
    col <- colorRampPalette(
            c("#67001F", "#B2182B", "#D6604D", "#F4A582",
              "#FDDBC7", "#FFFFFF", "#D1E5F0", "#92C5DE", 
             "#4393C3", "#2166AC", "#053061"))(200)
    col<-rev(col)
  }
  
  # Correlation matrix
  cormat<-signif(cor(x, use = "complete.obs", ...),2)
  pmat<-signif(cor.pmat(x, ...),2)
  # Reorder correlation matrix
  ord<-corrMatOrder(cormat, order="hclust")
  cormat<-cormat[ord, ord]
  pmat<-pmat[ord, ord]
  # Replace correlation coeff by symbols
  sym<-symnum(cormat, abbr.colnames=FALSE)
  # Correlogram
  if(graph & graphType[1]=="correlogram"){
    corrplot(cormat, type=ifelse(type[1]=="flatten", "lower", type[1]),
             tl.col="black", tl.srt=45,col=col,...)
  }
  else if(graphType[1]=="heatmap")
    heatmap(cormat, col=col, symm=TRUE)
  # Get lower/upper triangle
  if(type[1]=="lower"){
    cormat<-getLower.tri(cormat)
    pmat<-getLower.tri(pmat)
  }
  else if(type[1]=="upper"){
    cormat<-getUpper.tri(cormat)
    pmat<-getUpper.tri(pmat)
    sym=t(sym)
  }
  else if(type[1]=="flatten"){
    cormat<-flattenCorrMatrix(cormat, pmat)
    pmat=NULL
    sym=NULL
  }
  list(r=cormat, p=pmat, sym=sym)
}

```

```{r}
# install and load packages
list.of.packages <- c("data.table", "tidyverse", "gridExtra", "rlist", "Hmisc",
                      "corrplot","RColorBrewer")
lapply(list.of.packages, library, character.only = TRUE)


# read data as data table (enables multithreading)
df <- as.data.table(read_csv("CA_Data_HS19//train_taeglich.csv"))
# df <- as.data.table(read_csv("CA_Data_HS19//train_stuendlich.csv"))

# date as datetime
min(df[,date])
max(df[,date])
max(df[,date]) - min(df[,date])

# describe data
# head(df)
# dim(df)
```

# Prognose von Tagesumsätzen durch Entwicklung eines Prognosemodells mit vergangenen Daten

Daten: 

  - Umsatz- und Wetterdaten des Restaurant Schiffländi vom 18. September 2016 - 17. September 2019

  - Dimension: 1090 Tage, 23 Variablen

  - Unabhängige Variable: Umsatz in CHF (turnover)  
  
  - Abhängige Variabeln:  
  
    + Datumsvariablen: Datum (date), Tag im Monat (mdayN), Monat/Jahr (month, year), Wochentag (wday/wdayN), Wochennumer (weekN),  Kalendertag/Kalenderwoche (ydayN, yweekN)  
  
    + Feiertage und Ferien: lokale Schulferien (hls/hslL), lokale Feiertage (hl/hlL), Feiertag am vorherigen oder folgenden Tag (hlL.1, hlL1), Anzahl halber Feiertage pro Woche (hhn)  
  
    + Wettervariablen: relative Feuchtigkeit (hr), Niederschlagsmenge (ppt), Temperatur (tmp), Schneemenge (sf), Sonnenschein (sun), Wind (ws)  

```{r}
str(df, give.attr = FALSE)
```


```{r}
# timeseries plot turnover
p <- ggplot(data=df, aes(date, turnover)) +
  geom_point(color="blue") + 
  theme_bw() +
  scale_x_date(date_breaks = "1 month", date_labels =  "%b %Y") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
p
```



# Deskriptive Analyse

```{r}
summary(df)
```

Achtung: negative Werte für die Sonnenscheindauer! $\rightarrow$ Negative Werte werden durch den Durchschnitt vom vorherigen und dem folgenden Tag ersetzt.


```{r}
# negative minutes of sunshine!!!
summary(df[,sun])
df[sun<0, sun]
outlier_dates <- df[sun < 0, date]
df[date %in% c(outlier_dates),]

# missing values on 27.5.2017 + 2018
# recommendation: fill na by average of previous and following values of sun shine 

mean_value_1 <- df[
  date == as.Date(outlier_dates[1])-1 |
    date == as.Date(outlier_dates[1])+1,
  mean(sun)
  ]
mean_value_2 <- df[
  date == as.Date(outlier_dates[2])-1 |
    date == as.Date(outlier_dates[2])+1,
  mean(sun)
  ]
mean_values <- c(mean_value_1,mean_value_2)
# print(mean_values)

df[(sun < 0) & (date == outlier_dates[1]), "sun"] <- mean_value_1
df[(sun < 0) & (date == outlier_dates[2]), "sun"] <- mean_value_1

summary(df[,sun])
```



## Aggregierte Mittelwerte

```{r label colnames}
nums <- colnames(dplyr::select_if(df, is.numeric))
chars <- colnames(dplyr::select_if(df, is.character))
logicals <- colnames(dplyr::select_if(df, is.logical))
factors <- c(chars,logicals)


dep_var <- "turnover"
indep_vars <- factors

for (i in indep_vars){
  dt <- df[, .(mean(turnover)), keyby=i]
  out <- setorder(dt, -V1)
  print(out)
  print(" ")
}

```


## Scatterplots

```{r}
# scatterplot turnover against weather variables
dep_var <- "turnover"
indep_vars <- colnames(df)

indep_vars <- nums
for (i in seq(1,length(indep_vars), to=1)){
  p <- ggplot(df, aes_string(x=indep_vars[i], y=dep_var)) + 
    #labs(x=labels_df[i], y=tail(labels_df,1)) +
    geom_point(color="blue") + 
    theme(axis.text.x = element_text(angle=60, hjust=1)) 
  p <- p + geom_smooth()
  print(p)
}
```


## Boxplots
```{r}
# boxplot turnover against date vars + snow fraction
indep_vars <- c(chars,logicals)
dep_var <- "turnover"
for (i in seq(1,length(indep_vars), by=1)){
  p <- ggplot(df, aes_string(x=indep_vars[i], y=dep_var)) + 
    #labs(x=labels_df[i], y=tail(labels_df,1)) +
    geom_boxplot(color="blue") + 
    theme(axis.text.x = element_text(angle=60, hjust=1)) 
  print(p)
}


p <- ggplot(df, aes(x=year, y=turnover)) + 
  #labs(x=labels_df[i], y=tail(labels_df,1)) +
  geom_boxplot(color="blue") + 
  theme(axis.text.x = element_text(angle=60, hjust=1)) 
print(p)

```



## Kandidaten für die multivariate Analyse

  - Datumsvariablen: Der mittlere Jahresumsatz ist zwischen 2016 und 2019 angestiegen. Dabei ist er in den Sommermonaten höher als im restlichen Jahr. Weiter ist der Umsatz an den Wochenenden (Freitag bis Sonntag) höher als an Arbeitstagen.
  $\rightarrow$ Variablen: year, month, wday/wdayN 

  - Feiertage und Ferien: Der Umsatz schwankt stark über die verschiedenen Feiertagen und Ferien. Zum Beispiel liegt er an gewissen Feiertagen über dem Jahresmittel, an anderen deutlich darunter (1. August vs. Reformierungssonntag). Während den Auffahrtstagen liegt er besonders hoch. Ebenfalls liegt er höher an Tagen vor Feiertagen. 
  ?Anzahl halber Feiertage pro Woche (hhn)?
  $\rightarrow$ Variablen: hl/hlL, hls/hlsL, hlL.1
    
  - Wettervariablen: Der Umsatz variert stark je nach Wetter. Er ist höher bei trockenen, windstillen und sonnigen Wetter mit höheren Temperaturen (und keinem Schnee). 
    $\rightarrow$ hr, ppt, tmp, sf, sun, ws

## Carrelogram - Korrelationsanalyse

```{r}
rquery.cormat(dplyr::select_if(df, is.numeric))

```

  - Bereits als Kategorien codierte Variabeln werden bevorzugt. Demnach sind die folgenden Variabeln Kandidaten für die multivariate Analyse: **year, month, wday, hl, hls, hlL.1, hr, ppt, tmp, sf, sun, ws**  
  - Allerdings sind diese Variabeln sind teilweise stark korreliert (40-60\%) und deshalb ist deren Aussagekraft im Modell möglicherweise verzerrt. Wir behalten dies im Kopf und fahren mit den genannten Variabeln fort. 
  
Frage: Wie stark dürfen die abhängigen Variabeln im linearen Modell korrelieren? 


# Lineares Regressionsmodell

Strategie: Stepwise Regression (forward selection)

```{r}
# Linear Model Function
linear_model <- function(df, formula, str_splitDate){
  
  # Train / Test split
  splitDate <- as.POSIXct(str_splitDate) 
  train <- df[date < splitDate]
  test <- df[date >= splitDate]
  test.turnover <- test[,turnover]
  test[,turnover := NULL]
  
  range(train$date)
  range(test$date)
  
  
  # Modell fit
  lm.mod1 <- lm(formula, data = train)
  print(summary(lm.mod1))
  plot(lm.mod1)
  
  
  # Predict
  lm.mod1.pred <- predict(lm.mod1, newdata = test)
  plot(lm.mod1.pred)
  
  lm.mod1.res <- lm.mod1.pred - test.turnover
  ape <- abs(lm.mod1.res) / test.turnover
  mape <- median(ape)

  print(paste0("Formula: ", formula))
  print(paste0("Median APE: ", mape))



  # Plot
  plotdata <- data.table(pred = lm.mod1.pred, turnover = test.turnover, res = lm.mod1.res, ape = ape, date = test$date)
  
  predPlot <- ggplot(plotdata, aes(as.Date(date))) +
    geom_line(aes(y = turnover, colour = "Turnover")) +
    geom_line(aes(y = pred, colour = "Prediction")) +
    theme_bw() +
    scale_x_date(date_breaks = "1 week", date_labels =  "%d.%m.%Y") +
    theme(axis.text.x = element_text(angle = 60, hjust = 1))

  apePlot <- ggplot(plotdata, aes(as.Date(date))) +
    geom_line(aes(y = ape, colour = "Abweichung [%]")) +
    theme_bw() +
    scale_x_date(date_breaks = "1 week", date_labels =  "%d.%m.%Y") +
    theme(axis.text.x = element_text(angle = 60, hjust = 1))

  grid.arrange(predPlot, apePlot, nrow = 1)
  
  print(plotdata[order(-abs(res))])
  
}


# Global Variables
df <- df
str_splitDate <- "2019-06-01"

```


## Model 1

```{r}
formula <- turnover ~ factor(month)
linear_model(df=df, formula=formula, str_splitDate=str_splitDate)
```

## Model 2
```{r}
formula <- turnover ~ factor(month) + factor(wday)
linear_model(df=df, formula=formula, str_splitDate=str_splitDate)
```


## Model 3
```{r}
formula <- turnover ~ factor(month) + factor(wday) + factor(hlsL)
linear_model(df=df, formula=formula, str_splitDate=str_splitDate)
```

## Model 4
```{r}
formula <- turnover ~ factor(month) + factor(wday) + factor(hlsL) + sun
linear_model(df=df, formula=formula, str_splitDate=str_splitDate)
```

## Model 5
```{r}
formula <- turnover ~ factor(month) + factor(wday) + factor(hlsL) + sun + hr
linear_model(df=df, formula=formula, str_splitDate=str_splitDate)
```

## Model 6
```{r}
formula <- turnover ~ factor(month) + factor(wday) + factor(hlsL) + sun + hr + ppt
linear_model(df=df, formula=formula, str_splitDate=str_splitDate)
```

## Model 7
```{r}
formula <- turnover ~ factor(month) + factor(wday) + sun*factor(hlsL) + hr + ppt
linear_model(df=df, formula=formula, str_splitDate=str_splitDate)
```


## Modell Overfitting?
```{r}
formula <- turnover ~ factor(month)*factor(year) + factor(wday) + factor(hlL)*factor(hlsL) + sun + hr + ppt + tmp
linear_model(df=df, formula=formula, str_splitDate=str_splitDate)
```


# Weitere Forschungsansätze
  
  - Verteilung der Residuen zeigen "fat tailes", daher könnte ein lineares Modell mit t-verteilten Standardfehler die Daten besser fitten.  
  
  - Nicht-lineare Modelle wie Random Forest oder Neurales Netzwerk  
  


